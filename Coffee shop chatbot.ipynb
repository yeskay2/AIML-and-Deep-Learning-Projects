{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHortin91SfYtD64MueopD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"gO26po-kNSn1","executionInfo":{"status":"ok","timestamp":1679218660817,"user_tz":-330,"elapsed":369,"user":{"displayName":"RANIL TECH","userId":"09505576952358504499"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import random\n","\n","input_vocab = ['order coffee', 'order tea', 'order pastry']\n","output_vocab = ['Sure, what type of coffee would you like?', 'Sure, what type of tea would you like?', 'Sure, what type of pastry would you like?']\n","\n","max_input_len = max([len(i.split()) for i in input_vocab])\n","max_output_len = max([len(o.split()) for o in output_vocab])\n","\n","input_word2idx = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n","input_idx2word = {0: '<pad>', 1: '<start>', 2: '<end>', 3: '<unk>'}\n","output_word2idx = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}\n","output_idx2word = {0: '<pad>', 1: '<start>', 2: '<end>', 3: '<unk>'}\n","\n","for word in input_vocab:\n","    for char in word.split():\n","        if char not in input_word2idx:\n","            input_word2idx[char] = len(input_word2idx)\n","            input_idx2word[len(input_idx2word)] = char\n","for word in output_vocab:\n","    for char in word.split():\n","        if char not in output_word2idx:\n","            output_word2idx[char] = len(output_word2idx)\n","            output_idx2word[len(output_idx2word)] = char\n","\n","encoder_inputs = []\n","decoder_inputs = []\n","decoder_targets = []\n","\n","for input_word in input_vocab:\n","    encoder_input = [input_word2idx.get(char, 3) for char in input_word.split()]\n","    encoder_inputs.append(encoder_input)\n","\n","for output_word in output_vocab:\n","    decoder_input = [output_word2idx.get(char, 3) for char in (\"<start> \" + output_word).split()]\n","    decoder_target = [output_word2idx.get(char, 3) for char in (output_word + \" <end>\").split()]\n","    decoder_inputs.append(decoder_input)\n","    decoder_targets.append(decoder_target)\n","\n","encoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(encoder_inputs, maxlen=max_input_len, padding='post')\n","decoder_inputs = tf.keras.preprocessing.sequence.pad_sequences(decoder_inputs, maxlen=max_output_len, padding='post')\n","decoder_targets = tf.keras.preprocessing.sequence.pad_sequences(decoder_targets, maxlen=max_output_len, padding='post')\n","\n","input_shape = (max_input_len,)\n","output_shape = (max_output_len,)\n","\n","encoder_inputs_layer = tf.keras.layers.Input(input_shape)\n","encoder_embedding_layer = tf.keras.layers.Embedding(len(input_word2idx), 256)(encoder_inputs_layer)\n","encoder_lstm_layer = tf.keras.layers.LSTM(256, return_sequences=True, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm_layer(encoder_embedding_layer)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs_layer = tf.keras.layers.Input(output_shape)\n","decoder_embedding_layer = tf.keras.layers.Embedding(len(output_word2idx), 256)(decoder_inputs_layer)\n","decoder_lstm_layer = tf.keras.layers\n"]}]}